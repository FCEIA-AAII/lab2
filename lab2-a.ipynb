{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2a: Clasificación Binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FCEIA-AAII/lab1/blob/main/lab2-a.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno.\n",
    "\n",
    "Si no estamos parados en el repo, clonar y cd al repo. Esto nos permite usar el mismo notebook tanto local como en Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "REPO_NAME = \"lab2\"\n",
    "if REPO_NAME not in os.getcwd():\n",
    "  if not os.path.exists(REPO_NAME):\n",
    "    !git clone https://github.com/FCEIA-AAII/{REPO_NAME}.git\n",
    "  os.chdir(REPO_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Exploratorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar y visualizar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset-lab2.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = data['X1'].to_numpy()\n",
    "X2 = data['X2'].to_numpy()\n",
    "Y = data['Y'].to_numpy()\n",
    "\n",
    "print(\"X1 shape:\", X1.shape)\n",
    "print(\"X2 shape:\", X2.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "plt.scatter(X1[Y == 0], X2[Y == 0], color='red', alpha=0.5)\n",
    "plt.scatter(X1[Y == 1], X2[Y == 1], color='green', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Promedio Parciales')\n",
    "plt.ylabel('Promedio TPs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestro modelo usando tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,)),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función para plotear la frontera de decisión sobre los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(X1, X2, Y, model):\n",
    "    plt.scatter(X1[Y == 0], X2[Y == 0], color='red', alpha=0.5)\n",
    "    plt.scatter(X1[Y == 1], X2[Y == 1], color='green', alpha=0.5)\n",
    "\n",
    "    plt.xlabel('Promedio Parciales')\n",
    "    plt.ylabel('Promedio TPs')\n",
    "\n",
    "    x1 = np.linspace(0, 1, 100)\n",
    "    x2 = np.linspace(0, 1, 100)\n",
    "\n",
    "    # Create a meshgrid with all the possible combinations of x1 and x2\n",
    "    x1, x2 = np.meshgrid(x1, x2, indexing='ij')\n",
    "\n",
    "    # This is equivalent to\n",
    "    # x = np.array([[i, j] for i in x1 for j in x2])\n",
    "    x = np.array([x1.ravel(), x2.ravel()]).T\n",
    "\n",
    "    # Predict the value for each point in the meshgrid\n",
    "    y = model.predict(x).reshape(x1.shape)\n",
    "\n",
    "    # Use cmap red and green\n",
    "    plt.contourf(x1, x2, y, alpha=0.1, cmap='RdYlGn')\n",
    "\n",
    "    # Draw the decision boundary\n",
    "    plt.contour(x1, x2, y, levels=[0.5], colors='blue')\n",
    "\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_results(X1, X2, Y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El optimizador es el algoritmo que se encarga de minimizar la función de costo\n",
    "# Más adelante vamos a ver más en detalle cómo funciona cada uno\n",
    "# Por ahora, usamos el optimizador Adam, es una versión mejorada de gradient descent.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.5)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "x = np.column_stack([X1, X2])\n",
    "y = Y\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "model.fit(x=x, y=y, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot de la frontera de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(X1, X2, Y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el modelo no tiene la complejidad suficiente como para representar la frontera de decisión.\n",
    "\n",
    "Probemos entonces con un modelo más complejo.\n",
    "\n",
    "*Nota: el entrenamiento puede no converger a una solución óptima. Se propone correr el entrenamiento varias veces hasta que se obtenga una solución aceptable. Más adelante estudiaremos técnicas para mejorar la convergencia.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Completar con:\n",
    "    # 1. Una capa de entrada con las dimensiones correspondientes.\n",
    "    # 2. Una capa oculta con 2 neuronas y función de activación sigmoid.\n",
    "    # 3. Una capa de salida con 1 neurona y función de activación sigmoid.\n",
    "])\n",
    "\n",
    "# Pueden probar con distintos valores de learning rate y ver cómo afecta el entrenamiento\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.5)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=x, y=y, epochs=50)\n",
    "\n",
    "plot_results(X1, X2, Y, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
